{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Seagrass Segmentation (Drive Tiles) — Google Colab\n",
        "===================================================\n",
        "This notebook trains a **neural-network (U‑Net) classifier** using the training\n",
        "patches you showed in Drive:\n",
        "\n",
        "\n",
        "My Drive / GEOG 761_proj_training /\n",
        "├─ composites/ # yearly summer composites (multi-band .tif)\n",
        "├─ RGB Composites/ # RGB-only composites (optional)\n",
        "└─ training_patches_32tile/\n",
        "├─ images/ # input image tiles (*.tif)\n",
        "└─ labels/ # label tiles (*.tif) with class ids\n",
        "\n",
        "\n",
        "It then runs **sliding‑window inference** on any composite GeoTIFF and writes a\n",
        "classified raster (GeoTIFF) with class ids.\n",
        "\n",
        "\n",
        "Class codes (expected in label tiles):\n",
        "0 = background (ignored during training)\n",
        "1 = sparse seagrass\n",
        "2 = dense seagrass\n",
        "3 = exposed sediments\n",
        "4 = water\n",
        "5 = interfaces (water–sediment)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UQeE_DKu9Pn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLew4w31GCpM"
      },
      "outputs": [],
      "source": [
        "#!pip install earthengine-api geopandas shapely rasterio numpy pandas scikit-learn tensorflow==2.15 tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install rasterio"
      ],
      "metadata": {
        "id": "0ZiL8AFxXvJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geemap\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import os, glob, json, math\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "from rasterio.enums import Resampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "dDIqBkFhGSQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 1) MOUNT DRIVE & PATHS\n",
        "# ================================\n",
        "\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "\n",
        "ROOT = '/content/drive/My Drive/GEOG 761_proj_training'\n",
        "IM_DIR = f'{ROOT}/training_patches_32tile/images'\n",
        "LB_DIR = f'{ROOT}/training_patches_32tile/labels'\n",
        "COMPOSITES_DIR = f'{ROOT}/composites'\n",
        "OUT_PRED = f'{ROOT}/predictions' # will be created\n",
        "os.makedirs(OUT_PRED, exist_ok=True)"
      ],
      "metadata": {
        "id": "MSEiMAItXVz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 2) DISCOVER TRAINING TILES (images ⇄ labels)\n",
        "# ================================\n",
        "\n",
        "\n",
        "img_files = sorted(glob.glob(f'{IM_DIR}/*.tif'))\n",
        "# Match by basename existing in labels\n",
        "pairs = []\n",
        "for img in img_files:\n",
        "  base = os.path.basename(img)\n",
        "  lb = os.path.join(LB_DIR, base)\n",
        "  if os.path.exists(lb):\n",
        "    pairs.append((img, lb))\n",
        "\n",
        "\n",
        "assert len(pairs) > 0, 'No matching image/label tile pairs found.'\n",
        "print(f'Found {len(pairs)} tile pairs.')\n",
        "\n",
        "\n",
        "# Peek first tile to infer shapes and band count\n",
        "with rasterio.open(pairs[0][0]) as s:\n",
        "  H, W = s.height, s.width\n",
        "  C = s.count\n",
        "print(f'Tile size: {H}x{W}, bands: {C}')"
      ],
      "metadata": {
        "id": "ChJM2rx8XZLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 3) LOAD TILES INTO MEMORY (small dataset friendly)\n",
        "# ================================\n",
        "\n",
        "\n",
        "X_list, y_list = [], []\n",
        "for i, (im, lb) in enumerate(pairs):\n",
        "  with rasterio.open(im) as src:\n",
        "    arr = src.read() # (C,H,W)\n",
        "  with rasterio.open(lb) as src:\n",
        "    lab = src.read(1) # (H,W) integer class ids (0..5)\n",
        "  X_list.append(arr.transpose(1,2,0).astype('float32')) # (H,W,C)\n",
        "  y_list.append(lab.astype('int32'))\n",
        "\n",
        "\n",
        "X = np.stack(X_list, axis=0) # (N,H,W,C)\n",
        "y = np.stack(y_list, axis=0) # (N,H,W)\n",
        "print('Data shapes:', X.shape, y.shape)"
      ],
      "metadata": {
        "id": "2aKiJNTKXcDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 4) NORMALIZE & SPLIT\n",
        "# ================================\n",
        "\n",
        "\n",
        "# Per‑channel standardization using train split only\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "mean = X_train.mean(axis=(0,1,2), keepdims=True)\n",
        "std = X_train.std(axis=(0,1,2), keepdims=True) + 1e-6\n",
        "X_train_n = (X_train - mean) / std\n",
        "X_val_n = (X_val - mean) / std\n",
        "\n",
        "\n",
        "# Save scaler for inference\n",
        "os.makedirs('/content/artefacts', exist_ok=True)\n",
        "with open('/content/artefacts/scaler.json','w') as f:\n",
        "  json.dump({'mean': mean.squeeze().tolist(), 'std': std.squeeze().tolist()}, f)\n",
        "\n",
        "\n",
        "# Optional: compute class weights (ignore 0 during weighting)\n",
        "classes_present = np.unique(y_train)\n",
        "classes_present = classes_present[classes_present>0]\n",
        "cls_w = compute_class_weight('balanced', classes=classes_present, y=y_train[y_train>0])\n",
        "class_weight = {int(c): float(w) for c, w in zip(classes_present, cls_w)}\n",
        "print('Class weights (excluding 0):', class_weight)\n",
        "\n",
        "\n",
        "# Build pixel‑wise weights to **ignore background (0)**\n",
        "def make_sample_weights(y_batch):\n",
        "  # weight 0 for background pixels; others from class_weight\n",
        "  w = np.zeros_like(y_batch, dtype='float32')\n",
        "  for c, cw in class_weight.items():\n",
        "    w[y_batch==c] = cw\n",
        "  return w\n",
        "\n",
        "\n",
        "sw_train = make_sample_weights(y_train)\n",
        "sw_val = make_sample_weights(y_val)"
      ],
      "metadata": {
        "id": "3aIalrcY9jEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 5) MODEL — light U‑Net\n",
        "# ================================\n",
        "\n",
        "\n",
        "def conv_block(x, f):\n",
        "  x = tf.keras.layers.Conv2D(f, 3, padding='same', activation='relu')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2D(f, 3, padding='same', activation='relu')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  return x\n",
        "\n",
        "\n",
        "def encoder_block(x, f):\n",
        "  c = conv_block(x, f)\n",
        "  p = tf.keras.layers.MaxPool2D()(c)\n",
        "  return c, p\n",
        "\n",
        "\n",
        "def decoder_block(x, skip, f):\n",
        "  x = tf.keras.layers.Conv2DTranspose(f, 2, strides=2, padding='same')(x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skip])\n",
        "  x = conv_block(x, f)\n",
        "  return x\n",
        "\n",
        "\n",
        "#inputs = tf.keras.Input(shape=(H, W, C))\n",
        "inputs = tf.keras.Input(shape=(None, None, C))\n",
        "\n",
        "\n",
        "s1, p1 = encoder_block(inputs, 32)\n",
        "s2, p2 = encoder_block(p1, 64)\n",
        "s3, p3 = encoder_block(p2, 128)\n",
        "\n",
        "\n",
        "bottleneck = conv_block(p3, 256)\n",
        "\n",
        "\n",
        "d1 = decoder_block(bottleneck, s3, 128)\n",
        "d2 = decoder_block(d1, s2, 64)\n",
        "d3 = decoder_block(d2, s1, 32)\n",
        "\n",
        "\n",
        "outputs = tf.keras.layers.Conv2D(6, 1, activation='softmax')(d3) # classes: 0..5\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Loss that supports per‑pixel sample weights\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "  tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "  X_train_n, y_train[..., None],\n",
        "  validation_data=(X_val_n, y_val[..., None], sw_val), # weights for val reported\n",
        "  sample_weight=sw_train,\n",
        "  epochs=80,\n",
        "  batch_size=8,\n",
        "  callbacks=callbacks,\n",
        "  verbose=1)\n",
        "\n",
        "\n",
        "model.save('/content/artefacts/seagrass_unet.keras')\n",
        "print('Saved model to /content/artefacts/seagrass_unet.keras')"
      ],
      "metadata": {
        "id": "Gtb86fNKaQfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 6) INFERENCE — classify ALL composite GeoTIFFs\n",
        "# ================================\n",
        "\n",
        "composites = sorted(glob.glob(f'{COMPOSITES_DIR}/*.tif'))\n",
        "assert len(composites) > 0, 'No composite GeoTIFFs found.'\n",
        "print('Found composites:', [os.path.basename(p) for p in composites])\n",
        "\n",
        "# Load scaler\n",
        "with open('/content/artefacts/scaler.json','r') as f:\n",
        "    sc = json.load(f)\n",
        "mu = np.array(sc['mean'], dtype='float32')\n",
        "sigma = np.array(sc['std'], dtype='float32')\n",
        "\n",
        "WIN = 256  # multiple of 8\n",
        "\n",
        "for TARGET in composites:\n",
        "    print('Classifying:', os.path.basename(TARGET))\n",
        "\n",
        "    # open source explicitly to keep it alive while writing\n",
        "    src = rasterio.open(TARGET, 'r')\n",
        "    try:\n",
        "        profile = src.profile\n",
        "        bands_total = src.count\n",
        "        Hc, Wc = src.height, src.width\n",
        "\n",
        "        # Use first C bands; error if fewer than C\n",
        "        if bands_total < C:\n",
        "            raise ValueError(\n",
        "                f'{os.path.basename(TARGET)} has {bands_total} bands; model trained on {C}.'\n",
        "            )\n",
        "        band_indexes = list(range(1, C + 1))\n",
        "\n",
        "        out_path = os.path.join(\n",
        "            OUT_PRED,\n",
        "            os.path.basename(TARGET).replace('.tif', '_PRED.tif')\n",
        "        )\n",
        "        out_profile = profile.copy()\n",
        "        out_profile.update({'count': 1, 'dtype': 'uint8', 'nodata': 0})\n",
        "\n",
        "        with rasterio.open(out_path, 'w', **out_profile) as dst:\n",
        "            for r0 in range(0, Hc, WIN):\n",
        "                for c0 in range(0, Wc, WIN):\n",
        "                    h = min(WIN, Hc - r0)\n",
        "                    w = min(WIN, Wc - c0)\n",
        "                    win = Window(c0, r0, w, h)\n",
        "\n",
        "                    block = src.read(indexes=band_indexes, window=win)  # (C,h,w)\n",
        "                    x = block.transpose(1, 2, 0)[None, ...].astype('float32')\n",
        "\n",
        "                    # pad edge windows\n",
        "                    if h < WIN or w < WIN:\n",
        "                        x_pad = np.zeros((1, WIN, WIN, C), dtype='float32')\n",
        "                        x_pad[:, :h, :w, :] = x\n",
        "                        x = x_pad\n",
        "\n",
        "                    x = (x - mu) / sigma\n",
        "                    p = model.predict(x, verbose=0)[0]\n",
        "                    pred = np.argmax(p, axis=-1).astype('uint8')[:h, :w]\n",
        "\n",
        "                    dst.write(pred, 1, window=win)\n",
        "\n",
        "        print('Saved:', out_path)\n",
        "    finally:\n",
        "        src.close()\n",
        "\n",
        "print('Legend: 0=background, 1=sparse, 2=dense, 3=sediments, 4=water, 5=interfaces')\n"
      ],
      "metadata": {
        "id": "XnUmrV9tdfg6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}