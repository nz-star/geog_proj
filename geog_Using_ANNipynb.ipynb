{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Using ANN, SVR and RFR to estimate seagrass percentage coverage"
      ],
      "metadata": {
        "id": "acjySSLfF-nr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbgGtqZQF9qK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "root_dir = '/content/gdrive/My Drive/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers, utils, backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import shap\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import models\n",
        "\n",
        "from keras import layers\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "\n",
        "import xlrd"
      ],
      "metadata": {
        "id": "vylwfFJrGGOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = xlrd.open_workbook('/content/gdrive/My Drive/seagrass_coverage/original_data.xlsx')\n",
        "\n",
        "sheet = table.sheets()[0]\n",
        "\n",
        "x1 = sheet.col_values(6,1) #Band Blue\n",
        "\n",
        "x2 = sheet.col_values(7,1) #Band Green\n",
        "\n",
        "x3 = sheet.col_values(8,1) #Band Red\n",
        "\n",
        "x4 = sheet.col_values(9,1) #Band NIR\n",
        "\n",
        "x5 = sheet.col_values(10,1) #NDWI\n",
        "\n",
        "x6 = sheet.col_values(11,1) #NDVI\n",
        "\n",
        "x = np.array([x1,x2,x3,x4,x5,x6]).T #Transpose the array\n",
        "\n",
        "y = np.array(sheet.col_values(5,1))/100 #seagrass percentage coverage\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2) #Split the data; 80% for training\n",
        "\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_test,y_test,test_size = 0.5) #10% for validation and 10% for testing"
      ],
      "metadata": {
        "id": "h8FR5_hlGILI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import math\n",
        "\n",
        "result = []\n",
        "\n",
        "for m in range(2,40,2):\n",
        "  tf.keras.backend.clear_session()\n",
        "  model = models.Sequential()\n",
        "  tf.random.set_seed(1)\n",
        "  model.add(layers.Dense(m, activation = 'relu', input_shape = (x_train.shape[1], ))) ##Change different activation functions to find out the best one.\n",
        "  model.add(layers.Dense(m, activation = 'relu')),\n",
        "  model.add(layers.Dense(1,))\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.01) ##Change different Learning rate to find out the best one.\n",
        "  model.compile(opt, loss = 'mse', metrics = ['mse'])\n",
        "  model.fit(x_train,y_train,epochs = 1000,batch_size = 300, verbose = 0)\n",
        "  y_val_test = model.predict(x_val)\n",
        "  r2 = r2_score(y_val,y_val_test)\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "#The optimal values:\n",
        "\n",
        "#Number of hidden layers: 2 [Please check the methods in the paper]\n",
        "\n",
        "#Number of neurons : 10\n",
        "\n",
        "#Activation function: ReLu\n",
        "\n",
        "#Learning rate: 0.01"
      ],
      "metadata": {
        "id": "nzsl5FHSGQrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1)\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model.add(layers.Dense(10, activation = 'relu', input_shape = (x_train.shape[1], )))\n",
        "\n",
        "model.add(layers.Dense(10,activation = 'relu')),\n",
        "\n",
        "model.add(layers.Dense(1,))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "model.compile(opt, loss = 'mse', metrics = ['mse'])\n",
        "\n",
        "reuslt = model.fit(x_train,y_train,epochs = 1000,batch_size = 300, verbose = 0)\n",
        "\n",
        "y_test_predict = model.predict(x_test)\n",
        "\n",
        "plt.figure(figsize=[5,5])\n",
        "\n",
        "plt.scatter(y_test,y_test_predict)\n",
        "\n",
        "xx = [0,1]\n",
        "\n",
        "yy = [0,1]\n",
        "\n",
        "plt.plot(xx,yy,'-')\n",
        "\n",
        "plt.xlim([0,1])\n",
        "\n",
        "plt.ylim([0,1])\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import math\n",
        "\n",
        "print(math.sqrt(mean_squared_error(y_test_predict.flatten(),y_test.flatten())))\n",
        "\n",
        "# 0.11175243324504268\n",
        "\n",
        "print(r2_score(y_test_predict,y_test))\n",
        "\n",
        "# 0.7106385173472587"
      ],
      "metadata": {
        "id": "MSM-GTfQGTLk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}